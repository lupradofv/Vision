{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca376cb5",
   "metadata": {
    "papermill": {
     "duration": 0.043615,
     "end_time": "2022-02-27T17:50:27.004181",
     "exception": false,
     "start_time": "2022-02-27T17:50:26.960566",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### HARRIS\n",
    "- imagen a escala de grises \n",
    "- filtro Sobel en X y en Y\n",
    "        -> filtrar el ruido con un filtro gaussiano\n",
    "- encontrar matriz de covarianza\n",
    "- ecuacion R de harris = det - k(trace)^2\n",
    "- normalizar R\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "68279eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Implementa aquí tu código\n",
    "img = cv2.imread('images/0.jpg')\n",
    "# convertir a escala de grises\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "blur = cv2.GaussianBlur(gray,(5,5),0)\n",
    "\n",
    "sobelx = cv2.Sobel(blur,cv2.CV_64F,1,0,ksize=5)\n",
    "sobely = cv2.Sobel(blur,cv2.CV_64F,0,1,ksize=5)\n",
    "\n",
    "window_size = 5\n",
    "height, width = img.shape[:2]\n",
    "dx2 = sobelx**2\n",
    "dy2 = sobely**2\n",
    "dxy = sobelx*sobely\n",
    "matrix_R = np.zeros((height, width))\n",
    "k = 0.04\n",
    "\n",
    "offset = int( window_size / 2 )\n",
    "\n",
    "print (\"Finding Corners...\")\n",
    "for y in range(offset, height-offset):\n",
    "    for x in range(offset, width-offset):\n",
    "        Sx2 = np.sum(dx2[y-offset:y+1+offset, x-offset:x+1+offset])\n",
    "        Sy2 = np.sum(dy2[y-offset:y+1+offset, x-offset:x+1+offset])\n",
    "        Sxy = np.sum(dxy[y-offset:y+1+offset, x-offset:x+1+offset])\n",
    "\n",
    "        #   H(x,y)=[[Sx2,Sxy],[Sxy,Sy2]]\n",
    "        H = np.array([[Sx2,Sxy],[Sxy,Sy2]])\n",
    "\n",
    "        #   R=det(H)-k(Trace(H))^2 )\n",
    "        # Implementa aquí tu código para calcular R\n",
    "        R  = np.linalg.det(H) - k*(np.trace(H)**2)\n",
    "        matrix_R[y-offset, x-offset]=R\n",
    "\n",
    "print(matrix_R)\n",
    "\n",
    "threshold = 0.3\n",
    "\n",
    "cv2.normalize(matrix_R, matrix_R, 0, 1, cv2.NORM_MINMAX)\n",
    "for y in range(offset, height-offset):\n",
    "    for x in range(offset, width-offset):\n",
    "        value=matrix_R[y, x]\n",
    "        if value>threshold:\n",
    "            # Implementa aquí tu código, pero pintamos los circulos mucho mas pequeños\n",
    "            cv2.circle(img, (x, y), 1, (0, 0, 255), 1)\n",
    "                \n",
    "# Implementa aquí tu código para visualizar los resultados\n",
    "plt.imshow(img)\n",
    "plt.title(f'Harris Corner Detection T = {threshold}')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d38c2ee8",
   "metadata": {},
   "source": [
    "### Aplicación del método Hough para convertir  edges en boundaries. \n",
    "- imagen en RGB\n",
    "- filtro de canny a la imagen original \n",
    "- Hough para conseguir ver las lineas en la imagen \"hough-ex.jpg\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "973f34a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "# Implementa aquí tu código\n",
    "# aplicamos la funcion houghlinesP para convertir los edges en boundaries\n",
    "image = cv2.imread('images/hough-ex.jpg')\n",
    "image = cv2.cvtColor(image,cv2.COLOR_BGR2RGB)\n",
    "low_threshold = 50\n",
    "high_threshold = 100\n",
    "\n",
    "edges = cv2.Canny(image,low_threshold,high_threshold,apertureSize = 3)\n",
    "rho = 1\n",
    "theta = np.pi/180\n",
    "threshold = 30\n",
    "min_line_length = 200\n",
    "max_line_gap = 3\n",
    "line_image = np.copy(image) #creating an image copy to draw lines on# Run Hough on the edge-detected image\n",
    "\n",
    "# Implementa aquí tu código para llamar a HoughLinesP\n",
    "lines = cv2.HoughLinesP(edges,rho,theta,threshold,min_line_length,max_line_gap)\n",
    "\n",
    "\n",
    "\n",
    "# Implementa aquí tu código para visualizar las líneas calculadas\n",
    "for line in lines:\n",
    "    for x1,y1,x2,y2 in line:\n",
    "        cv2.line(line_image,(x1,y1),(x2,y2),(0,255,0),1)\n",
    "\n",
    "plt.imshow(line_image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a5a6e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Implementa aquí tu código\n",
    "\n",
    "# comparamos nuestra deteccion de corners con la implementacion de OpenCV\n",
    "\n",
    "img = cv2.imread('images/0.jpg')\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "gray = np.float32(gray) # la convertimos a float32 ya que cv2.cornerHarris lo requiere\n",
    "\n",
    "# Implementa aquí tu código\n",
    "windows = [3,5,7,9,11,13,15,17,19,21]\n",
    "kernels = [3,5,7,9,11,13,15,17,19,21]\n",
    "k = 0.04\n",
    "t = [0.01,0.02,0.03,0.04,0.05,0.06,0.07, 0.1, 0.2, 0.3, 0.4, 0.5] # \n",
    "\n",
    "# number corners detected\n",
    "n = []\n",
    "for window in windows:\n",
    "    for kernel in kernels:\n",
    "        for threshold in t:\n",
    "            dst = cv2.cornerHarris(gray,window,kernel,k) # k es el parametro libre de la ecuacion, es \n",
    "            dst = cv2.dilate(dst,None) # dilatamos los corners para que se vean mejor\n",
    "            img[dst>threshold*dst.max()]=[0,0,255]\n",
    "            # contamos el numero de corners detectados\n",
    "            n.append(np.sum(dst>threshold*dst.max()))\n",
    "\n",
    "# cogemos el mejor resultado, el mas cerca de 1000\n",
    "best = np.argmin(np.abs(np.array(n)-1000))\n",
    "index = np.unravel_index(best, (len(windows), len(kernels), len(t)))\n",
    "\n",
    "# veamos como queda con los mejores parametros\n",
    "img = cv2.imread('images/0.jpg')\n",
    "window_size = windows[index[0]]\n",
    "kernel_size = kernels[index[1]]\n",
    "threshold = t[index[2]]\n",
    "print(f'Best parameters: window_size={window_size}, kernel_size={kernel_size}, threshold={threshold}')\n",
    "dst = cv2.cornerHarris(gray,window_size,kernel_size,k)\n",
    "dst = cv2.dilate(dst,None)\n",
    "img[dst>threshold*dst.max()]=[0,0,255] # multiplicamos el threshold por el valor maximo de dst para que sea un valor absoluto\n",
    "\n",
    "# Implementa aquí tu código para visualizar los resultados\n",
    "plt.imshow(img)\n",
    "plt.title(f'OpenCV Harris Corner Detection with T = {threshold}')\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e0ca660",
   "metadata": {},
   "source": [
    "### SIFT DETECTOR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35a39b10",
   "metadata": {},
   "source": [
    "- imagen en gris\n",
    "- detectar blobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bbfc2737",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install pandas\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "932b968f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "from skimage import data\n",
    "from skimage.feature import blob_dog, blob_log, blob_doh\n",
    "from skimage.color import rgb2gray\n",
    " \n",
    "import matplotlib.pyplot as plt\n",
    " \n",
    "image=cv2.imread('images/hough-ex.jpg')\n",
    "#image = data.hubble_deep_field()[0:500, 0:500]\n",
    "image_gray = rgb2gray(image)\n",
    "# aplicar la función de detección de blobs a la imagen en escala de grises blob_log\n",
    "blobs_log = blob_log(image_gray, max_sigma=30, threshold=0.1)\n",
    "# Compute radii in the 3rd column.\n",
    "blobs_log[:, 2] = blobs_log[:, 2] * sqrt(2)\n",
    " \n",
    "blobs_dog = blob_dog(image_gray, max_sigma=30, threshold=0.1)\n",
    "blobs_dog[:, 2] = blobs_dog[:, 2] * sqrt(2)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "12c23883",
   "metadata": {},
   "outputs": [],
   "source": [
    "dim=(1024,768)\n",
    "left = cv2.imread('images/car0.jpg')\n",
    "right = cv2.imread('images/car1.jpg')\n",
    "left=cv2.resize(left,dim,interpolation=cv2.INTER_AREA)\n",
    "right=cv2.resize(right,dim,interpolation=cv2.INTER_AREA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7645fa01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stitching(img1, img2, min_match_count = 10):\n",
    "    sift = cv2.SIFT_create()\n",
    "    \n",
    "    \n",
    "    keypoints1, descriptors1 = sift.detectAndCompute(img1, None)\n",
    "    keypoints2, descriptors2 = sift.detectAndCompute(img2, None)\n",
    "    \n",
    "    \n",
    "    FLANN_INDEX_KDTREE = 0\n",
    "    index_params = dict(algorithm = FLANN_INDEX_KDTREE, trees = 5)\n",
    "    search_params = dict(checks = 50)\n",
    "    \n",
    "    \n",
    "    flann = cv2.FlannBasedMatcher(index_params, search_params)\n",
    "    \n",
    "    \n",
    "    matches = flann.knnMatch(descriptors1, descriptors2, k=2)\n",
    "    \n",
    "   \n",
    "    # Implementa aquí tu código para calcular tus \"good matches\"\n",
    "    good_matches = []\n",
    "    for m,n in matches:\n",
    "        if m.distance < 0.75*n.distance:\n",
    "            good_matches.append(m)\n",
    "\n",
    "    img3 = cv2.drawMatchesKnn(left,keypoints1,right,keypoints2,good_matches,None,flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)\n",
    "    plt.imshow(img3),plt.show()\n",
    "            \n",
    "    if len(good_matches) > min_match_count:\n",
    "        src_pts = np.float32([ keypoints1[good_match.queryIdx].pt\n",
    "                              for good_match in good_matches ]).reshape(-1,1,2)\n",
    "        \n",
    "        dst_pts = np.float32([ keypoints2[good_match.trainIdx].pt \n",
    "                              for good_match in good_matches ]).reshape(-1,1,2)\n",
    "        \n",
    "        M, mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC, 5.0)\n",
    "        result = warpImages(img2, img1, M)\n",
    "        return result\n",
    "    \n",
    "    else:\n",
    "        print (\"We don't have enough number of matches between the two images.\")\n",
    "        print (\"Found only \" + str(len(good_matches)) + \" matches.\")\n",
    "        print (\"We need at least \" + str(min_match_count) + \" matches.\")\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dc06d14d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def showplt(image, title=None, pltnative=False):\n",
    "    if pltnative: \n",
    "        plt.imshow(image)\n",
    "    else: \n",
    "        plt.imshow(image[...,::-1])\n",
    "    plt.title(title)\n",
    "    plt.xticks([]), plt.yticks([]) \n",
    "    plt.show()\n",
    "    \n",
    "def warpImages(img1, img2, H):\n",
    "    rows1, cols1 = img1.shape[:2]\n",
    "    rows2, cols2 = img2.shape[:2]\n",
    "    \n",
    "    list_of_points_1 = np.float32([\n",
    "        [0,0], \n",
    "        [0,rows1],\n",
    "        [cols1,rows1], \n",
    "        [cols1,0]\n",
    "    ])\n",
    "    list_of_points_1 = list_of_points_1.reshape(-1,1,2)\n",
    "\n",
    "    temp_points = np.float32([\n",
    "        [0,0], \n",
    "        [0,rows2], \n",
    "        [cols2,rows2],\n",
    "        [cols2,0]\n",
    "    ])\n",
    "    temp_points = temp_points.reshape(-1,1,2)\n",
    "    \n",
    "    list_of_points_2 = cv2.perspectiveTransform(temp_points, H)\n",
    "    \n",
    "    list_of_points = np.concatenate((list_of_points_1, list_of_points_2), axis=0)\n",
    "    \n",
    "    ##Define boundaries:\n",
    "    [x_min, y_min] = np.int32(list_of_points.min(axis=0).ravel() - 0.5)\n",
    "    [x_max, y_max] = np.int32(list_of_points.max(axis=0).ravel() + 0.5)\n",
    "    \n",
    "    translation_dist = [-x_min,-y_min]\n",
    "    \n",
    "    H_translation = np.array([[1, 0, translation_dist[0]], [0, 1, translation_dist[1]], [0,0,1]])\n",
    "    \n",
    "    output_img = cv2.warpPerspective(img2, \n",
    "                                     H_translation.dot(H), \n",
    "                                     (x_max - x_min, y_max - y_min))\n",
    "    ## Paste the image:\n",
    "    output_img[translation_dist[1]:rows1+translation_dist[1], \n",
    "               translation_dist[0]:cols1+translation_dist[0]] = img1\n",
    "    \n",
    "    return output_img\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "614bfee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "stitch_image = stitching(left,right)\n",
    " \n",
    "alto, ancho = stitch_image.shape[:2]\n",
    "centro = (ancho // 2, alto // 2)\n",
    "matriz_rotacion = cv2.getRotationMatrix2D(centro, 270, 1.0)\n",
    "imagen_rotada = cv2.warpAffine(stitch_image, matriz_rotacion, (ancho, alto))\n",
    "showplt(imagen_rotada)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13 (main, Aug 25 2022, 18:29:29) \n[Clang 12.0.0 ]"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 35.35951,
   "end_time": "2022-02-27T17:50:51.135837",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-02-27T17:50:15.776327",
   "version": "2.3.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "e518e308cad670d7b1fcf9f087692433d6126550cb57a6b3caeb90934ca4b540"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
